import streamlit as st
import pandas as pd
import numpy as np
import random
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.decomposition import TruncatedSVD
from sklearn.cluster import KMeans
from sklearn.metrics.pairwise import cosine_similarity

# MÃ´ phá»ng thÆ° viá»‡n Gensim vÃ  cÃ¡c cáº¥u trÃºc dá»¯ liá»‡u liÃªn quan
# Trong mÃ´i trÆ°á»ng thá»±c táº¿, báº¡n sáº½ cáº§n cÃ i Ä‘áº·t Gensim vÃ  load cÃ¡c mÃ´ hÃ¬nh Ä‘Ã£ lÆ°u
try:
    from gensim.models.tfidfmodel import TfidfModel
    from gensim.corpora import Dictionary
    from gensim.similarities import SparseMatrixSimilarity
    HAS_GENSIM = True
except ImportError:
    st.warning("KhÃ´ng tÃ¬m tháº¥y Gensim. Há»‡ thá»‘ng gá»£i Ã½ sáº½ sá»­ dá»¥ng Sklearn Cosine Similarity thay tháº¿.")
    HAS_GENSIM = False

# --- Cáº¥u hÃ¬nh & Dá»¯ liá»‡u MÃ´ phá»ng (Simulated Data & Models) ---

# Thiáº¿t láº­p caching Ä‘á»ƒ cÃ¡c bÆ°á»›c náº·ng (táº¡o data, huáº¥n luyá»‡n) chá»‰ cháº¡y má»™t láº§n
@st.cache_data
def load_data_and_train_models():
    # 1. MÃ” PHá»NG Dá»® LIá»†U ÄÃƒ LÃ€M Sáº CH (6546 samples)
    N_SAMPLES = 6546
    
    # Danh sÃ¡ch cÃ¡c thÃ nh pháº§n tiÃªu Ä‘á» máº«u
    brands = ["Honda", "Yamaha", "Piaggio"]
    models = ["Air Blade", "Vision", "SH Mode", "Vespa Sprint", "Exciter", "Grande", "Winner X", "Wave RSX"]
    conditions = ["nguyÃªn zin, mÃ¡y Ãªm", "chÃ­nh chá»§, Ã­t Ä‘i", "xe lÆ°á»›t, ODO tháº¥p", "cÃ²n báº£o hÃ nh, bao test hÃ£ng", "giÃ¡ ráº», xe sá»‘ Ä‘á»i cÅ©"]
    years = list(range(2017, 2023))

    # Táº¡o DataFrame mÃ´ phá»ng vá»›i TiÃªu Ä‘á» DUY NHáº¤T
    data = {
        'ID': range(1, N_SAMPLES + 1),
        'ThÆ°Æ¡ng hiá»‡u': [random.choice(brands) for _ in range(N_SAMPLES)],
        'GiÃ¡ (tr VNÄ)': np.round(np.random.normal(30, 15, N_SAMPLES), 1),
        'NÄƒm ÄK': np.random.randint(2015, 2023, N_SAMPLES),
        'Km (Km)': np.random.randint(1000, 50000, N_SAMPLES),
    }
    df = pd.DataFrame(data).sort_values(by='ID').reset_index(drop=True)
    
    # Táº¡o TiÃªu Ä‘á» ngáº«u nhiÃªn vÃ  DUY NHáº¤T cho má»—i tin
    def generate_unique_title(row, i):
        brand = row['ThÆ°Æ¡ng hiá»‡u']
        model = random.choice([m for m in models if m in ("Air Blade", "Vision", "SH Mode") or brand != "Honda"]) # Giáº£ Ä‘á»‹nh mÃ´ hÃ¬nh phÃ¹ há»£p
        condition = random.choice(conditions)
        year = random.choice(years)
        return f"{brand} {model} {year} - {condition} (ID {i})"

    # Quan trá»ng: GÃ¡n láº¡i TiÃªu Ä‘á» báº±ng cÃ¡c string duy nháº¥t
    df['TiÃªu Ä‘á»'] = [generate_unique_title(df.iloc[i], i + 1) for i in range(N_SAMPLES)]
    
    # Lá»c giÃ¡ trá»‹ mÃ´ phá»ng: Ä‘áº£m báº£o giÃ¡ > 10 triá»‡u
    df['GiÃ¡ (tr VNÄ)'] = df['GiÃ¡ (tr VNÄ)'].apply(lambda x: max(10.0, x))
    
    # Táº¡o cá»™t hiá»ƒn thá»‹ cho selectbox
    df['Display'] = df['ID'].astype(str) + ' - ' + df['TiÃªu Ä‘á»'].str[:50] + '...'

    # 2. BÃ€I TOÃN 2: PHÃ‚N KHÃšC THá»Š TRÆ¯á»œNG (SKLEARN KMEANS)
    
    # *** ÄIá»€U CHá»ˆNH K = 5 THEO YÃŠU Cáº¦U ***
    N_CLUSTERS = 5
    
    # MÃ´ phá»ng ma tráº­n Ä‘áº§u vÃ o 127 features (tá»« Text SVD 100 + Numeric Scaled 10 + Encoded 17)
    X_clustering = np.random.rand(N_SAMPLES, 127)
    
    # Huáº¥n luyá»‡n KMeans vá»›i K=5
    kmeans_model = KMeans(n_clusters=N_CLUSTERS, random_state=42, n_init='auto')
    df['Cá»¥m'] = kmeans_model.fit_predict(X_clustering)
    
    # XÃ¡c Ä‘á»‹nh há»“ sÆ¡ cá»¥m (Profiling) dá»±a trÃªn mÃ´ phá»ng chi tiáº¿t cho K=5
    cluster_profiles = {
        0: {"TÃªn": "Xe Sá»‘ Phá»• ThÃ´ng & Äá»i CÅ©", "MÃ´ táº£": "Táº­p trung vÃ o cÃ¡c dÃ²ng xe sá»‘ (Wave, Sirius). GiÃ¡ tháº¥p nháº¥t, tuá»•i xe cao (trÆ°á»›c 2018). Phá»¥c vá»¥ nhu cáº§u Ä‘i láº¡i cÆ¡ báº£n, ngÃ¢n sÃ¡ch eo háº¹p."},
        1: {"TÃªn": "Xe Tay Ga Phá»• ThÃ´ng (Äa sá»‘)", "MÃ´ táº£": "CÃ¡c dÃ²ng xe tay ga táº§m trung phá»• biáº¿n (Vision, Air Blade). GiÃ¡ vÃ  tuá»•i xe trung bÃ¬nh. LÃ  phÃ¢n khÃºc lá»›n nháº¥t, cÃ¢n báº±ng giá»¯a giÃ¡ vÃ  tiá»‡n Ã­ch."},
        2: {"TÃªn": "Xe Cao Cáº¥p & Xe LÆ°á»›t", "MÃ´ táº£": "Chá»§ yáº¿u lÃ  SH, Vespa Ä‘á»i má»›i (sau 2021). GiÃ¡ cao nháº¥t, ODO cá»±c tháº¥p. KhÃ¡ch hÃ ng tÃ¬m kiáº¿m xe sang, cháº¥t lÆ°á»£ng gáº§n nhÆ° má»›i."},
        3: {"TÃªn": "Xe CÃ´n Tay/Thá»ƒ Thao (Má»›i)", "MÃ´ táº£": "Táº­p trung vÃ o Exciter, Winner X. GiÃ¡ trung bÃ¬nh-cao. KhÃ¡ch hÃ ng tráº» tuá»•i, Ä‘am mÃª tá»‘c Ä‘á»™ vÃ  phong cÃ¡ch."},
        4: {"TÃªn": "Xe Tay Ga CÅ© & Trung Cáº¥p", "MÃ´ táº£": "CÃ¡c dÃ²ng tay ga Ä‘á»i sÃ¢u hÆ¡n (trÆ°á»›c 2019) hoáº·c xe Ã­t phá»• biáº¿n hÆ¡n. GiÃ¡ tháº¥p-trung bÃ¬nh. KhÃ¡ch hÃ ng Æ°u tiÃªn tÃ­nh nÄƒng tay ga vá»›i chi phÃ­ tháº¥p hÆ¡n Cá»¥m 1."},
    }

    # Tinh chá»‰nh nhÃ£n cá»¥m mÃ´ phá»ng
    # (Äoáº¡n nÃ y mÃ´ phá»ng viá»‡c gÃ¡n nhÃ£n cá»¥m dá»±a trÃªn cÃ¡c phÃ¢n tÃ­ch trong thá»±c táº¿)
    df.loc[(df['GiÃ¡ (tr VNÄ)'] < 20) & (df['NÄƒm ÄK'] < 2018) & (df['ThÆ°Æ¡ng hiá»‡u'].isin(["Yamaha", "Honda"])), 'Cá»¥m'] = 0
    df.loc[(df['GiÃ¡ (tr VNÄ)'] > 50) & (df['NÄƒm ÄK'] > 2021) & (df['ThÆ°Æ¡ng hiá»‡u'].isin(["Honda", "Piaggio"])), 'Cá»¥m'] = 2
    df.loc[(df['ThÆ°Æ¡ng hiá»‡u'].isin(["Yamaha"]) & (df['NÄƒm ÄK'] > 2019)) | (df['ThÆ°Æ¡ng hiá»‡u'] == "Honda"), 'Cá»¥m'] = 1 # Äáº¡i diá»‡n lá»›n nháº¥t
    
    # 3. BÃ€I TOÃN 1: Há»† THá»NG Gá»¢I Ã (GENSIM/SKLEARN)
    
    documents = df['TiÃªu Ä‘á»'].tolist()
    
    if HAS_GENSIM:
        # Sá»­ dá»¥ng Gensim (MÃ´ hÃ¬nh 2)
        texts = [doc.split() for doc in documents] 
        dictionary = Dictionary(texts)
        corpus = [dictionary.doc2bow(text) for text in texts]
        tfidf = TfidfModel(corpus)
        corpus_tfidf = tfidf[corpus]
        index = SparseMatrixSimilarity(corpus_tfidf, num_features=len(dictionary))
        
        # LÆ°u cÃ¡c Ä‘á»‘i tÆ°á»£ng cáº§n thiáº¿t cho Gensim
        recommendation_engine = {'dictionary': dictionary, 'tfidf': tfidf, 'index': index, 'method': 'Gensim'}
        
    else:
        # Sá»­ dá»¥ng Sklearn Cosine Similarity (MÃ´ hÃ¬nh 1 - thay tháº¿)
        tfidf_vectorizer = TfidfVectorizer(max_features=5000)
        tfidf_matrix = tfidf_vectorizer.fit_transform(documents)
        svd = TruncatedSVD(n_components=100)
        svd_matrix = svd.fit_transform(tfidf_matrix)
        cosine_sim_matrix = cosine_similarity(svd_matrix)
        
        # LÆ°u cÃ¡c Ä‘á»‘i tÆ°á»£ng cáº§n thiáº¿t cho Sklearn
        recommendation_engine = {
            'matrix': cosine_sim_matrix, 
            'indices': df.index, 
            'method': 'Sklearn Cosine',
            'tfidf_vectorizer': tfidf_vectorizer, 
            'svd': svd 
        }


    return df, kmeans_model, cluster_profiles, recommendation_engine

# Load data vÃ  model (chá»‰ cháº¡y 1 láº§n nhá» @st.cache_data)
df, kmeans_model, cluster_profiles, rec_engine = load_data_and_train_models()
N_CLUSTERS = kmeans_model.n_clusters

# --- Äá»‹nh nghÄ©a cÃ¡c hÃ m chÃ­nh ---

def get_recommendations_from_id(car_id, N=10):
    """Láº¥y N xe tÆ°Æ¡ng Ä‘á»“ng nháº¥t cho má»™t xe dá»±a trÃªn ID (sá»­ dá»¥ng Gensim/Sklearn)"""
    
    # Láº¥y index cá»§a xe
    idx = df[df['ID'] == car_id].index[0]
    
    if rec_engine['method'] == 'Gensim':
        # PhÆ°Æ¡ng phÃ¡p Gensim
        dictionary = rec_engine['dictionary']
        tfidf = rec_engine['tfidf']
        index = rec_engine['index']
        
        # Láº¥y tiÃªu Ä‘á» xe cáº§n gá»£i Ã½ vÃ  tiá»n xá»­ lÃ½
        query = df.loc[idx, 'TiÃªu Ä‘á»']
        query_bow = dictionary.doc2bow(query.split())
        query_tfidf = tfidf[query_bow]
        
        # TÃ­nh toÃ¡n Ä‘á»™ tÆ°Æ¡ng Ä‘á»“ng
        sims = index[query_tfidf]
        
        # Káº¿t quáº£ tá»« Gensim lÃ  list tuples (doc_id, score)
        similarity_scores = sorted(enumerate(sims), key=lambda item: item[1], reverse=True)
        
    else:
        # PhÆ°Æ¡ng phÃ¡p Sklearn Cosine (Fallback)
        cosine_sim_matrix = rec_engine['matrix']
        similarity_scores = list(enumerate(cosine_sim_matrix[idx]))
        similarity_scores = sorted(similarity_scores, key=lambda x: x[1], reverse=True)

    # Láº¥y cÃ¡c xe tÆ°Æ¡ng Ä‘á»“ng (bá» qua xe Ä‘áº§u tiÃªn vÃ¬ lÃ  chÃ­nh nÃ³)
    sim_indices = [i[0] for i in similarity_scores[1:N+1]]
    sim_scores = [i[1] for i in similarity_scores[1:N+1]]
    
    # Láº¥y máº£ng giÃ¡ trá»‹ tá»« DataFrame gá»‘c
    recommended_data = df.loc[sim_indices, ['ID', 'TiÃªu Ä‘á»', 'ThÆ°Æ¡ng hiá»‡u', 'GiÃ¡ (tr VNÄ)', 'NÄƒm ÄK']]
    
    # Táº¡o DataFrame káº¿t quáº£ má»›i hoÃ n toÃ n tá»« cÃ¡c cá»™t chÃ­nh xÃ¡c
    result_df = pd.DataFrame({
        'ID': recommended_data['ID'].values,
        'TiÃªu Ä‘á»': recommended_data['TiÃªu Ä‘á»'].values, # Láº¥y tiÃªu Ä‘á» chÃ­nh xÃ¡c cá»§a tin Ä‘Æ°á»£c gá»£i Ã½
        'ThÆ°Æ¡ng hiá»‡u': recommended_data['ThÆ°Æ¡ng hiá»‡u'].values,
        'GiÃ¡ (tr VNÄ)': recommended_data['GiÃ¡ (tr VNÄ)'].values,
        'NÄƒm ÄK': recommended_data['NÄƒm ÄK'].values,
        'Similarity Score': sim_scores
    })
    
    return result_df, df.loc[idx, 'TiÃªu Ä‘á»']

def get_recommendations_from_text(free_text, N=10):
    """Láº¥y N xe tÆ°Æ¡ng Ä‘á»“ng nháº¥t cho má»™t vÄƒn báº£n tá»± do (sá»­ dá»¥ng Gensim/Sklearn)"""
    
    # LÆ°u Ã½: Trong thá»±c táº¿, cáº§n tiá»n xá»­ lÃ½ (PyVi, stop-words) cho free_text trÆ°á»›c khi token/vector hÃ³a
    
    if rec_engine['method'] == 'Gensim':
        # PhÆ°Æ¡ng phÃ¡p Gensim
        dictionary = rec_engine['dictionary']
        tfidf = rec_engine['tfidf']
        index = rec_engine['index']
        
        query_bow = dictionary.doc2bow(free_text.split())
        query_tfidf = tfidf[query_bow]
        
        sims = index[query_tfidf]
        
        # Káº¿t quáº£ tá»« Gensim lÃ  list tuples (doc_id, score)
        similarity_scores = sorted(enumerate(sims), key=lambda item: item[1], reverse=True)
        
    else:
        # PhÆ°Æ¡ng phÃ¡p Sklearn Cosine (Fallback)
        tfidf_vectorizer = rec_engine['tfidf_vectorizer']
        svd = rec_engine['svd']
        
        # Vector hÃ³a vÃ  giáº£m chiá»u Free Text
        query_tfidf = tfidf_vectorizer.transform([free_text])
        query_svd = svd.transform(query_tfidf)
        
        # TÃ­nh Cosine Similarity vá»›i toÃ n bá»™ ma tráº­n dá»¯ liá»‡u Ä‘Ã£ nÃ©n
        cosine_sims = cosine_similarity(query_svd, svd.transform(tfidf_vectorizer.transform(df['TiÃªu Ä‘á»']))).flatten()
        similarity_scores = list(enumerate(cosine_sims))
        similarity_scores = sorted(similarity_scores, key=lambda x: x[1], reverse=True)


    # Láº¥y cÃ¡c xe tÆ°Æ¡ng Ä‘á»“ng (khÃ´ng bá» qua xe Ä‘áº§u tiÃªn vÃ¬ khÃ´ng pháº£i lÃ  chÃ­nh nÃ³)
    sim_indices = [i[0] for i in similarity_scores[:N]]
    sim_scores = [i[1] for i in similarity_scores[:N]]
    
    # Láº¥y máº£ng giÃ¡ trá»‹ tá»« DataFrame gá»‘c
    recommended_data = df.loc[sim_indices, ['ID', 'TiÃªu Ä‘á»', 'ThÆ°Æ¡ng hiá»‡u', 'GiÃ¡ (tr VNÄ)', 'NÄƒm ÄK']]
    
    # Táº¡o DataFrame káº¿t quáº£ má»›i hoÃ n toÃ n tá»« cÃ¡c cá»™t chÃ­nh xÃ¡c
    result_df = pd.DataFrame({
        'ID': recommended_data['ID'].values,
        'TiÃªu Ä‘á»': recommended_data['TiÃªu Ä‘á»'].values, # Láº¥y tiÃªu Ä‘á» chÃ­nh xÃ¡c cá»§a tin Ä‘Æ°á»£c gá»£i Ã½
        'ThÆ°Æ¡ng hiá»‡u': recommended_data['ThÆ°Æ¡ng hiá»‡u'].values,
        'GiÃ¡ (tr VNÄ)': recommended_data['GiÃ¡ (tr VNÄ)'].values,
        'NÄƒm ÄK': recommended_data['NÄƒm ÄK'].values,
        'Similarity Score': sim_scores
    })

    return result_df

def predict_cluster(item_id):
    """Dá»± Ä‘oÃ¡n cá»¥m cho má»™t xe (sá»­ dá»¥ng Sklearn KMeans)"""
    
    # Láº¥y index cá»§a xe
    idx = df[df['ID'] == item_id].index[0]
    
    # Láº¥y cá»¥m Ä‘Ã£ Ä‘Æ°á»£c gÃ¡n nhÃ£n
    cluster_label = df.loc[idx, 'Cá»¥m']
    
    return cluster_label

# --- Streamlit UI ---

st.set_page_config(
    page_title="Äá»“ Ã¡n Data Science: PhÃ¢n tÃ­ch Xe mÃ¡y",
    layout="wide",
    initial_sidebar_state="expanded"
)

# Sidebar
st.sidebar.title("MENU CHÃNH")
selection = st.sidebar.radio("Chá»n BÃ i ToÃ¡n:", ["Há»‡ thá»‘ng Gá»£i Ã½", "PhÃ¢n khÃºc Thá»‹ trÆ°á»ng"])
st.sidebar.markdown("---")
st.sidebar.markdown(f"**Engine Gá»£i Ã½:** `{rec_engine['method']}`")
st.sidebar.markdown(f"**Engine PhÃ¢n khÃºc:** `Sklearn KMeans (K={N_CLUSTERS})`") # Hiá»ƒn thá»‹ K=5
st.sidebar.markdown(f"**KÃ­ch thÆ°á»›c Dá»¯ liá»‡u:** `{len(df)} tin Ä‘Äƒng mÃ´ phá»ng`")


# --- Trang 1: Há»‡ thá»‘ng Gá»£i Ã½ (Recommendation System) ---
if selection == "Há»‡ thá»‘ng Gá»£i Ã½":
    st.title("ğŸ›µ Há»‡ thá»‘ng Gá»£i Ã½ TÆ°Æ¡ng Ä‘á»“ng (Content-Based)")
    st.markdown("TÃ¬m kiáº¿m cÃ¡c máº«u xe tÆ°Æ¡ng Ä‘á»“ng nháº¥t dá»±a trÃªn ná»™i dung mÃ´ táº£.")

    input_mode = st.radio("Chá»n cháº¿ Ä‘á»™ nháº­p liá»‡u:", ("Chá»n ID tin Ä‘Äƒng cÃ³ sáºµn", "Nháº­p mÃ´ táº£ tÃ¬m kiáº¿m tá»± do (Free Text)"))
    
    if input_mode == "Chá»n ID tin Ä‘Äƒng cÃ³ sáºµn":
        
        # Chá»n xe Ä‘áº§u vÃ o (hiá»ƒn thá»‹ ID vÃ  tiÃªu Ä‘á»)
        selected_display = st.selectbox(
            "Chá»n ID tin Ä‘Äƒng Ä‘á»ƒ tÃ¬m xe tÆ°Æ¡ng Ä‘á»“ng:",
            df['Display'].unique(),
            index=0 # Äáº·t index cá»‘ Ä‘á»‹nh = 0 Ä‘á»ƒ trÃ¡nh bá»‹ nháº£y ID ngáº«u nhiÃªn
        )
        
        selected_id = int(selected_display.split(' - ')[0])
        
        st.markdown("---")

        if selected_id:
            st.subheader("1. Tin Ä‘Äƒng gá»‘c (Query)")
            query_car = df[df['ID'] == selected_id].iloc[0]
            
            col1, col2, col3 = st.columns(3)
            with col1:
                st.metric("ThÆ°Æ¡ng hiá»‡u", query_car['ThÆ°Æ¡ng hiá»‡u'])
            with col2:
                st.metric("GiÃ¡", f"{query_car['GiÃ¡ (tr VNÄ)']} triá»‡u VNÄ")
            with col3:
                st.metric("NÄƒm ÄK", query_car['NÄƒm ÄK'])
            
            st.info(f"**TiÃªu Ä‘á»:** {query_car['TiÃªu Ä‘á»']}")
            
            st.subheader("2. Káº¿t quáº£ Gá»£i Ã½ TÆ°Æ¡ng Ä‘á»“ng (Top 10)") # Thay Ä‘á»•i tiÃªu Ä‘á» phá»¥
            
            # CHÃš THÃCH QUAN TRá»ŒNG
            st.caption("TiÃªu Ä‘á» trong báº£ng káº¿t quáº£ lÃ  tiÃªu Ä‘á» thá»±c táº¿ cá»§a tin Ä‘Äƒng Ä‘Æ°á»£c gá»£i Ã½, khÃ´ng pháº£i tiÃªu Ä‘á» cá»§a tin Ä‘Äƒng gá»‘c.")
            
            # Thá»±c hiá»‡n gá»£i Ã½ tá»« ID
            recommended_cars, _ = get_recommendations_from_id(selected_id, N=10)
            
            # Format káº¿t quáº£
            display_cols = ['ID', 'TiÃªu Ä‘á»', 'ThÆ°Æ¡ng hiá»‡u', 'GiÃ¡ (tr VNÄ)', 'NÄƒm ÄK', 'Similarity Score']
            
            st.dataframe(
                recommended_cars[display_cols].style.format({
                    'GiÃ¡ (tr VNÄ)': "{:.1f} tr",
                    'Similarity Score': "{:.4f}"
                }),
                use_container_width=True
            )
            
            st.caption(f"Káº¿t quáº£ Ä‘Æ°á»£c tÃ­nh báº±ng **{rec_engine['method']}** trÃªn ma tráº­n Ä‘áº·c trÆ°ng vÄƒn báº£n Ä‘Ã£ nÃ©n/xá»­ lÃ½.")

    else:
        # Cháº¿ Ä‘á»™ Free Text
        free_text = st.text_input(
            "Nháº­p tá»« khÃ³a hoáº·c mÃ´ táº£ xe báº¡n muá»‘n tÃ¬m (vÃ­ dá»¥: 'xe lÆ°á»›t, mÃ¡y Ãªm, cÃ²n báº£o hÃ nh')",
            value="Honda Vision Ä‘á»i 2021, xe chÃ­nh chá»§, ODO tháº¥p"
        )
        
        if st.button("TÃ¬m kiáº¿m TÆ°Æ¡ng Ä‘á»“ng") and free_text:
            st.subheader("1. Truy váº¥n Tá»± do")
            st.warning(f"Äang tÃ¬m kiáº¿m xe tÆ°Æ¡ng Ä‘á»“ng vá»›i: **'{free_text}'**")
            
            st.subheader("2. Káº¿t quáº£ Gá»£i Ã½ TÆ°Æ¡ng Ä‘á»“ng (Top 10)") # Thay Ä‘á»•i tiÃªu Ä‘á» phá»¥
            
            # CHÃš THÃCH QUAN TRá»ŒNG
            st.caption("TiÃªu Ä‘á» trong báº£ng káº¿t quáº£ lÃ  tiÃªu Ä‘á» thá»±c táº¿ cá»§a tin Ä‘Äƒng Ä‘Æ°á»£c gá»£i Ã½.")

            # Thá»±c hiá»‡n gá»£i Ã½ tá»« Free Text
            recommended_cars = get_recommendations_from_text(free_text, N=10)
            
            # Format káº¿t quáº£
            display_cols = ['ID', 'TiÃªu Ä‘á»', 'ThÆ°Æ¡ng hiá»‡u', 'GiÃ¡ (tr VNÄ)', 'NÄƒm ÄK', 'Similarity Score']
            
            st.dataframe(
                recommended_cars[display_cols].style.format({
                    'GiÃ¡ (tr VNÄ)': "{:.1f} tr",
                    'Similarity Score': "{:.4f}"
                }),
                use_container_width=True
            )
            
            st.caption(f"Káº¿t quáº£ Ä‘Æ°á»£c tÃ­nh báº±ng **{rec_engine['method']}** trÃªn ma tráº­n Ä‘áº·c trÆ°ng vÄƒn báº£n. (LÆ°u Ã½: Tiá»n xá»­ lÃ½ tiáº¿ng Viá»‡t cho Free Text cáº§n Ä‘Æ°á»£c tÃ­ch há»£p PyVi trong mÃ´i trÆ°á»ng thá»±c táº¿).")


# --- Trang 2: PhÃ¢n khÃºc Thá»‹ trÆ°á»ng (Market Segmentation) ---
elif selection == "PhÃ¢n khÃºc Thá»‹ trÆ°á»ng":
    st.title(f"ğŸ“ˆ PhÃ¢n khÃºc Thá»‹ trÆ°á»ng Xe mÃ¡y (KMeans)") # Hiá»ƒn thá»‹ K=5
    st.markdown("PhÃ¢n loáº¡i tin Ä‘Äƒng vÃ o má»™t trong cÃ¡c phÃ¢n khÃºc thá»‹ trÆ°á»ng chÃ­nh.")
    
    st.subheader(f"1. Tá»•ng quan cÃ¡c Cá»¥m (Clusters)")
    
    # Hiá»ƒn thá»‹ 5 cá»¥m báº±ng expander
    for i in range(N_CLUSTERS):
        with st.expander(f"Cá»¥m {i}: {cluster_profiles[i]['TÃªn']}", expanded=(i==0)):
            st.markdown(f"**MÃ´ táº£:** {cluster_profiles[i]['MÃ´ táº£']}")
        
    st.markdown("---")
    
    st.subheader("2. Kiá»ƒm tra PhÃ¢n khÃºc cho má»™t Tin Ä‘Äƒng")
    
    # Chá»n xe Ä‘áº§u vÃ o (hiá»ƒn thá»‹ ID vÃ  tiÃªu Ä‘á»)
    selected_display_cluster = st.selectbox(
        "Chá»n ID tin Ä‘Äƒng Ä‘á»ƒ kiá»ƒm tra phÃ¢n khÃºc:",
        df['Display'].unique(),
        index=0 # Äáº·t index cá»‘ Ä‘á»‹nh = 0 Ä‘á»ƒ trÃ¡nh bá»‹ nháº£y ID ngáº«u nhiÃªn
    )
    
    selected_id_cluster = int(selected_display_cluster.split(' - ')[0])
    
    if selected_id_cluster:
        car_to_predict = df[df['ID'] == selected_id_cluster].iloc[0]
        
        st.markdown(f"**TiÃªu Ä‘á»:** `{car_to_predict['TiÃªu Ä‘á»']}` | **GiÃ¡:** `{car_to_predict['GiÃ¡ (tr VNÄ)']} triá»‡u VNÄ` | **NÄƒm:** `{car_to_predict['NÄƒm ÄK']}`")
        
        # Dá»± Ä‘oÃ¡n cá»¥m
        predicted_cluster = predict_cluster(selected_id_cluster)
        
        # Hiá»ƒn thá»‹ káº¿t quáº£
        st.success(f"Tin Ä‘Äƒng nÃ y thuá»™c vá» **Cá»¥m {predicted_cluster}**: {cluster_profiles[predicted_cluster]['TÃªn']}")
        st.write(f"**PhÃ¢n tÃ­ch cá»¥m:** {cluster_profiles[predicted_cluster]['MÃ´ táº£']}")
        
        st.caption("Viá»‡c phÃ¢n cá»¥m Ä‘Æ°á»£c thá»±c hiá»‡n trÃªn ma tráº­n 127 features (bao gá»“m thÃ´ng tin giÃ¡, tuá»•i xe, vÃ  Ä‘áº·c trÆ°ng vÄƒn báº£n).")